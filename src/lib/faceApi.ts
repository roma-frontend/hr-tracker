import * as faceapi from 'face-api.js';

let modelsLoaded = false;

// Load face-api.js models
export async function loadFaceApiModels() {
  if (modelsLoaded) {
    console.log('‚ÑπÔ∏è Models already loaded');
    return;
  }

  const MODEL_URL = '/models'; // We'll place model files in public/models
  
  console.log('üì¶ Loading Face-API models from:', MODEL_URL);
  
  try {
    console.log('‚è≥ Loading SSD MobileNet v1...');
    await faceapi.nets.ssdMobilenetv1.loadFromUri(MODEL_URL);
    console.log('‚úÖ SSD MobileNet v1 loaded');
    
    console.log('‚è≥ Loading Face Landmark 68...');
    await faceapi.nets.faceLandmark68Net.loadFromUri(MODEL_URL);
    console.log('‚úÖ Face Landmark 68 loaded');
    
    console.log('‚è≥ Loading Face Recognition...');
    await faceapi.nets.faceRecognitionNet.loadFromUri(MODEL_URL);
    console.log('‚úÖ Face Recognition loaded');
    
    modelsLoaded = true;
    console.log('‚úÖ All Face-API models loaded successfully');
  } catch (error) {
    console.error('‚ùå Error loading Face-API models:', error);
    throw error;
  }
}

// Detect face and get descriptor
export async function detectFace(videoElement: HTMLVideoElement) {
  if (!modelsLoaded) {
    console.log("üì¶ Models not loaded, loading now...");
    await loadFaceApiModels();
  }

  // Verify video element is ready
  if (!videoElement || videoElement.readyState < 2) {
    console.warn("‚ö†Ô∏è Video element not ready for detection");
    return null;
  }

  try {
    const detection = await faceapi
      .detectSingleFace(videoElement, new faceapi.SsdMobilenetv1Options({ minConfidence: 0.5 }))
      .withFaceLandmarks()
      .withFaceDescriptor();

    if (detection) {
      console.log('üë§ Face detection result:', {
        score: detection.detection.score,
        box: detection.detection.box,
        descriptorLength: detection.descriptor.length
      });
    }

    return detection;
  } catch (error) {
    console.error("‚ùå Error detecting face:", error);
    return null;
  }
}

// Compare two face descriptors
export function compareFaces(descriptor1: Float32Array, descriptor2: number[]): number {
  const distance = faceapi.euclideanDistance(descriptor1, descriptor2);
  return distance;
}

// Check if face match is valid (threshold: 0.6 is common)
export function isFaceMatch(distance: number, threshold: number = 0.6): boolean {
  return distance < threshold;
}

// Find best matching face from a list
export function findBestMatch(
  inputDescriptor: Float32Array,
  knownDescriptors: { userId: string; name: string; descriptor: number[] }[]
): { userId: string; name: string; distance: number } | null {
  if (knownDescriptors.length === 0) return null;

  let bestMatch = {
    userId: knownDescriptors[0].userId,
    name: knownDescriptors[0].name,
    distance: compareFaces(inputDescriptor, knownDescriptors[0].descriptor),
  };

  for (let i = 1; i < knownDescriptors.length; i++) {
    const distance = compareFaces(inputDescriptor, knownDescriptors[i].descriptor);
    if (distance < bestMatch.distance) {
      bestMatch = {
        userId: knownDescriptors[i].userId,
        name: knownDescriptors[i].name,
        distance,
      };
    }
  }

  return bestMatch;
}

// Create canvas from video for display
export function createCanvasFromVideo(video: HTMLVideoElement): HTMLCanvasElement {
  const canvas = document.createElement('canvas');
  canvas.width = video.videoWidth;
  canvas.height = video.videoHeight;
  const ctx = canvas.getContext('2d');
  if (ctx) {
    ctx.drawImage(video, 0, 0);
  }
  return canvas;
}

// Convert canvas to blob for upload
export async function canvasToBlob(canvas: HTMLCanvasElement): Promise<Blob> {
  return new Promise((resolve, reject) => {
    canvas.toBlob((blob) => {
      if (blob) {
        resolve(blob);
      } else {
        reject(new Error('Failed to convert canvas to blob'));
      }
    }, 'image/jpeg', 0.95);
  });
}
